{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Dimensionality Reduction: Introduction </h1>\n",
    "\n",
    "\n",
    "<h2> Project Proposal </h2>\n",
    "\n",
    "\n",
    "The objective of this project is to reduce the tabular data's dimensionality, breaking down the range of disparate values into vectors which combine the meaninfgul signal contained in the data sources I have aggregated. This can enable faster processing of the data in other analyses such as decision trees or regression models, and it will also enable better performance by excluding noise from the data where possible. In terms of tools: I will use Python's scikit learn and its sub-package scikit learn.metrics, particularly the PCA and tSNE methods, to analyze the data and attempt dimensionality reduction. \n",
    "\n",
    "The record dataset I will be analyzing for dimensionality reduction includes: 1 - The daily level of retail activity for the top 10 most active stock tickers, 2 - The daily change in the level of retail activity for the top 10 most active stock tickers, 3 - Weekly individual investor survey data (columns for the percent of respondents that were bearish, bullish, or neutral), 4 - Weekly change in major stock indices prices, 4 - weekly stocktwits rankings of the most active stock tickers.\n",
    "\n",
    "The dataset described above was selected by using all of the available record data that I gathered for this project. This is because data pertaining to retail investor sentiment and trading is exceptionally scarce online, and so it makes sense to use all available data for topics such as dimensionality reduction. Text data was not used due to its fundamental differences from the record data, and computational requirements given the 10,000 columns.\n",
    "\n",
    "\n",
    "<h1> Code Implementation: </h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Read data in:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#--------------------------------------\n",
    "#USER PARAM \n",
    "#--------------------------------------\n",
    "\n",
    "NDIM                    =   3       #DIMENSION OF DATA\n",
    "L                       =   50      #BOX SIZE (DATA BOUNDS)\n",
    "NPOINTS=10000000    #int(np.random.uniform(low=100, high=300, size=1))\n",
    "\n",
    "\n",
    "#MEAN VECTOR \n",
    "u=0*np.random.uniform(-L,L,size=NDIM); \n",
    "\n",
    "#COVARIANCE MATRIX \n",
    "#cov(xi,xj) --> symetric\n",
    "#STD DEV VECTOR\n",
    "s=np.random.uniform(0.2*L,L/10,size=NDIM); \n",
    "cov = np.random.uniform(-L/10,L/10,size=(NDIM,NDIM))\n",
    "#FILL MAIN DIAG WITH STD DEV\n",
    "np.fill_diagonal(cov, s, wrap=False)\n",
    "#FORCE MATRIX TO BE POSITIVE SEMI-DEFINITE\n",
    "cov = np.dot(cov, cov.transpose())\n",
    "print('EXACT MEAN:',u)\n",
    "print(\"EXACT COV:\")\n",
    "print(cov)\n",
    "\n",
    "# SAMPLE\n",
    "X = np.random.multivariate_normal(u, cov, NPOINTS)\n",
    "print('\\nNUMERIC MEAN:',np.mean(X,axis=0))\n",
    "print(\"X SHAPE\",X.shape)\n",
    "print(\"NUMERIC COV:\")\n",
    "print(np.cov(X.T))\n",
    "\n",
    "# EIGEN VALUES/VECTOR\n",
    "from numpy import linalg as LA\n",
    "# w, v1 = LA.eig(cov)\n",
    "w, v1 = LA.eig(np.cov(X.T))\n",
    "print(\"\\nCOV EIGENVALUES:\",w)\n",
    "print(\"COV EIGENVECTORS (across rows):\")\n",
    "print(v1.T)\n",
    "\n",
    "# X = np.random.multivariate_normal(u, cov, NPOINTS)\n",
    "\n",
    "# PCA CALCULATION\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(X)\n",
    "print('\\nPCA')\n",
    "print(pca.components_)\n",
    "# v2=pca.components_\n",
    "\n",
    "# print(v1/v2)\n",
    "\n",
    "# # PLOT\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(projection='3d')\n",
    "# ax.scatter(X[:,0],X[:,1],X[:,2],marker=\".\", cmap=\"viridis\")\n",
    "# v1=v1*1000\n",
    "# # v2=v2*1000\n",
    "\n",
    "# ax.quiver(0,0,0,v1[0,0],v1[1,0],v1[2,0])\n",
    "# ax.quiver(0,0,0,v1[0,1],v1[1,1],v1[2,1])\n",
    "# ax.quiver(0,0,0,v1[0,2],v1[1,2],v1[2,2])\n",
    "\n",
    "# # ax.quiver(0,0,0,v2[0,0],v2[1,0],v2[2,0])\n",
    "# # ax.quiver(0,0,0,v2[0,1],v2[1,1],v2[2,1])\n",
    "# # ax.quiver(0,0,0,v2[0,2],v2[1,2],v2[2,2])\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Project Report </h1>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
